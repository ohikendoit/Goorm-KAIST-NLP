{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:28:01.108943Z",
     "iopub.status.busy": "2021-10-24T21:28:01.108662Z",
     "iopub.status.idle": "2021-10-24T21:28:07.275681Z",
     "shell.execute_reply": "2021-10-24T21:28:07.274712Z",
     "shell.execute_reply.started": "2021-10-24T21:28:01.108865Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import wandb\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    AutoConfig,\n",
    "    AdamW\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:05:14.091686Z",
     "iopub.status.busy": "2021-10-24T21:05:14.091032Z",
     "iopub.status.idle": "2021-10-24T21:05:14.098044Z",
     "shell.execute_reply": "2021-10-24T21:05:14.097299Z",
     "shell.execute_reply.started": "2021-10-24T21:05:14.091649Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_id_file(task, tokenizer):\n",
    "    def make_data_strings(file_name):\n",
    "        data_strings = []\n",
    "        with open(os.path.join('../input/goormtextclassificationproject', file_name), 'r', encoding='utf-8') as f:\n",
    "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
    "        for item in id_file_data:\n",
    "            data_strings.append(' '.join([str(k) for k in item]))\n",
    "        return data_strings\n",
    "    \n",
    "    print('it will take some times...')\n",
    "    train_pos = make_data_strings('sentiment.train.1')\n",
    "    train_neg = make_data_strings('sentiment.train.0')\n",
    "    dev_pos = make_data_strings('sentiment.dev.1')\n",
    "    dev_neg = make_data_strings('sentiment.dev.0')\n",
    "\n",
    "    print('make id file finished!')\n",
    "    return train_pos, train_neg, dev_pos, dev_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:05:15.841446Z",
     "iopub.status.busy": "2021-10-24T21:05:15.840891Z",
     "iopub.status.idle": "2021-10-24T21:05:20.5036Z",
     "shell.execute_reply": "2021-10-24T21:05:20.502899Z",
     "shell.execute_reply.started": "2021-10-24T21:05:15.841408Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:05:20.505189Z",
     "iopub.status.busy": "2021-10-24T21:05:20.504949Z",
     "iopub.status.idle": "2021-10-24T21:07:57.034951Z",
     "shell.execute_reply": "2021-10-24T21:07:57.033206Z",
     "shell.execute_reply.started": "2021-10-24T21:05:20.505155Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:00.592861Z",
     "iopub.status.busy": "2021-10-24T21:08:00.592452Z",
     "iopub.status.idle": "2021-10-24T21:08:00.601702Z",
     "shell.execute_reply": "2021-10-24T21:08:00.600822Z",
     "shell.execute_reply.started": "2021-10-24T21:08:00.592824Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:01.251292Z",
     "iopub.status.busy": "2021-10-24T21:08:01.250691Z",
     "iopub.status.idle": "2021-10-24T21:08:01.260285Z",
     "shell.execute_reply": "2021-10-24T21:08:01.259365Z",
     "shell.execute_reply.started": "2021-10-24T21:08:01.251247Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(object):\n",
    "    def __init__(self, tokenizer, pos, neg):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for pos_sent in pos:\n",
    "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
    "            self.label += [[1]]\n",
    "        for neg_sent in neg:\n",
    "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
    "            self.label += [[0]]\n",
    "        self.data = self.data[:1000]\n",
    "\n",
    "    def _cast_to_int(self, sample):\n",
    "        return [int(word_id) for word_id in sample]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return np.array(sample), np.array(self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:01.994746Z",
     "iopub.status.busy": "2021-10-24T21:08:01.99441Z",
     "iopub.status.idle": "2021-10-24T21:08:04.915342Z",
     "shell.execute_reply": "2021-10-24T21:08:04.914594Z",
     "shell.execute_reply.started": "2021-10-24T21:08:01.994715Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
    "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:06.066445Z",
     "iopub.status.busy": "2021-10-24T21:08:06.065969Z",
     "iopub.status.idle": "2021-10-24T21:08:06.07667Z",
     "shell.execute_reply": "2021-10-24T21:08:06.075849Z",
     "shell.execute_reply.started": "2021-10-24T21:08:06.066411Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(train_dataset):\n",
    "    print(item)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:06.674726Z",
     "iopub.status.busy": "2021-10-24T21:08:06.674262Z",
     "iopub.status.idle": "2021-10-24T21:08:06.682396Z",
     "shell.execute_reply": "2021-10-24T21:08:06.68173Z",
     "shell.execute_reply.started": "2021-10-24T21:08:06.674692Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn_style(samples):\n",
    "    input_ids, labels = zip(*samples)\n",
    "    max_len = max(len(input_id) for input_id in input_ids)\n",
    "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
    "\n",
    "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
    "                             batch_first=True)\n",
    "    attention_mask = torch.tensor(\n",
    "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
    "         sorted_indices])\n",
    "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
    "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
    "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:07.207743Z",
     "iopub.status.busy": "2021-10-24T21:08:07.20726Z",
     "iopub.status.idle": "2021-10-24T21:08:07.214411Z",
     "shell.execute_reply": "2021-10-24T21:08:07.213596Z",
     "shell.execute_reply.started": "2021-10-24T21:08:07.207708Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_size=64\n",
    "eval_batch_size=64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True, collate_fn=collate_fn_style,\n",
    "                                           pin_memory=True, num_workers=4)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
    "                                         shuffle=False, collate_fn=collate_fn_style,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "random_seed=42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:14.848735Z",
     "iopub.status.busy": "2021-10-24T21:08:14.848317Z",
     "iopub.status.idle": "2021-10-24T21:08:14.858048Z",
     "shell.execute_reply": "2021-10-24T21:08:14.857342Z",
     "shell.execute_reply.started": "2021-10-24T21:08:14.848698Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "learning_rate = 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:15.790643Z",
     "iopub.status.busy": "2021-10-24T21:08:15.790143Z",
     "iopub.status.idle": "2021-10-24T21:08:15.795368Z",
     "shell.execute_reply": "2021-10-24T21:08:15.794439Z",
     "shell.execute_reply.started": "2021-10-24T21:08:15.790601Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_acc(predictions, target_labels):\n",
    "    return (np.array(predictions) == np.array(target_labels)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:08:16.450622Z",
     "iopub.status.busy": "2021-10-24T21:08:16.449987Z",
     "iopub.status.idle": "2021-10-24T21:08:23.640238Z",
     "shell.execute_reply": "2021-10-24T21:08:23.639413Z",
     "shell.execute_reply.started": "2021-10-24T21:08:16.450578Z"
    }
   },
   "outputs": [],
   "source": [
    "train_epoch = 1\n",
    "lowest_valid_loss = 9999.\n",
    "for epoch in range(train_epoch):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            position_ids = position_ids.to(device)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           token_type_ids=token_type_ids,\n",
    "                           position_ids=position_ids,\n",
    "                           labels=labels)\n",
    "\n",
    "            loss = output.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
    "                # Evaluate the model five times per epoch\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    valid_losses = []\n",
    "                    predictions = []\n",
    "                    target_labels = []\n",
    "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
    "                                                                                                desc='Eval',\n",
    "                                                                                                position=1,\n",
    "                                                                                                leave=None):\n",
    "                        input_ids = input_ids.to(device)\n",
    "                        attention_mask = attention_mask.to(device)\n",
    "                        token_type_ids = token_type_ids.to(device)\n",
    "                        position_ids = position_ids.to(device)\n",
    "                        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                        output = model(input_ids=input_ids,\n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                       position_ids=position_ids,\n",
    "                                       labels=labels)\n",
    "\n",
    "                        logits = output.logits\n",
    "                        loss = output.loss\n",
    "                        valid_losses.append(loss.item())\n",
    "\n",
    "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
    "                        batch_labels = [int(example) for example in labels]\n",
    "\n",
    "                        predictions += batch_predictions\n",
    "                        target_labels += batch_labels\n",
    "\n",
    "                acc = compute_acc(predictions, target_labels)\n",
    "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
    "                if lowest_valid_loss > valid_loss:\n",
    "                    print('Acc for model which have lower valid loss: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:19:40.213214Z",
     "iopub.status.busy": "2021-10-24T21:19:40.212962Z",
     "iopub.status.idle": "2021-10-24T21:19:40.227601Z",
     "shell.execute_reply": "2021-10-24T21:19:40.22692Z",
     "shell.execute_reply.started": "2021-10-24T21:19:40.213184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('../input/goormtextclassificationproject/test_no_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:19:40.479077Z",
     "iopub.status.busy": "2021-10-24T21:19:40.478846Z",
     "iopub.status.idle": "2021-10-24T21:19:40.483838Z",
     "shell.execute_reply": "2021-10-24T21:19:40.482766Z",
     "shell.execute_reply.started": "2021-10-24T21:19:40.479051Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = test_df['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:19:40.983582Z",
     "iopub.status.busy": "2021-10-24T21:19:40.983364Z",
     "iopub.status.idle": "2021-10-24T21:19:40.988374Z",
     "shell.execute_reply": "2021-10-24T21:19:40.987681Z",
     "shell.execute_reply.started": "2021-10-24T21:19:40.983557Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_id_file_test(tokenizer, test_dataset):\n",
    "    data_strings = []\n",
    "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
    "    for item in id_file_data:\n",
    "        data_strings.append(' '.join([str(k) for k in item]))\n",
    "    return data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:19:41.246804Z",
     "iopub.status.busy": "2021-10-24T21:19:41.246527Z",
     "iopub.status.idle": "2021-10-24T21:19:41.624055Z",
     "shell.execute_reply": "2021-10-24T21:19:41.62344Z",
     "shell.execute_reply.started": "2021-10-24T21:19:41.246776Z"
    }
   },
   "outputs": [],
   "source": [
    "test = make_id_file_test(tokenizer, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:12:14.60112Z",
     "iopub.status.busy": "2021-10-24T21:12:14.600749Z",
     "iopub.status.idle": "2021-10-24T21:12:14.607618Z",
     "shell.execute_reply": "2021-10-24T21:12:14.606871Z",
     "shell.execute_reply.started": "2021-10-24T21:12:14.601084Z"
    }
   },
   "outputs": [],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:14:39.166445Z",
     "iopub.status.busy": "2021-10-24T21:14:39.166192Z",
     "iopub.status.idle": "2021-10-24T21:14:39.174714Z",
     "shell.execute_reply": "2021-10-24T21:14:39.173561Z",
     "shell.execute_reply.started": "2021-10-24T21:14:39.166415Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentimentTestDataset(object):\n",
    "    def __init__(self, tokenizer, test):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []\n",
    "\n",
    "        for sent in test:\n",
    "            self.data += [self._cast_to_int(sent.strip().split())]\n",
    "\n",
    "    def _cast_to_int(self, sample):\n",
    "        return [int(word_id) for word_id in sample]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return np.array(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:14:39.652006Z",
     "iopub.status.busy": "2021-10-24T21:14:39.651535Z",
     "iopub.status.idle": "2021-10-24T21:14:39.659923Z",
     "shell.execute_reply": "2021-10-24T21:14:39.658938Z",
     "shell.execute_reply.started": "2021-10-24T21:14:39.651965Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = SentimentTestDataset(tokenizer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:15:26.018936Z",
     "iopub.status.busy": "2021-10-24T21:15:26.018653Z",
     "iopub.status.idle": "2021-10-24T21:15:26.026633Z",
     "shell.execute_reply": "2021-10-24T21:15:26.02577Z",
     "shell.execute_reply.started": "2021-10-24T21:15:26.018904Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn_style_test(samples):\n",
    "    input_ids = samples\n",
    "    max_len = max(len(input_id) for input_id in input_ids)\n",
    "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
    "\n",
    "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
    "                             batch_first=True)\n",
    "    attention_mask = torch.tensor(\n",
    "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
    "         sorted_indices])\n",
    "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
    "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:18:09.655625Z",
     "iopub.status.busy": "2021-10-24T21:18:09.654771Z",
     "iopub.status.idle": "2021-10-24T21:18:09.661488Z",
     "shell.execute_reply": "2021-10-24T21:18:09.660777Z",
     "shell.execute_reply.started": "2021-10-24T21:18:09.655571Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 40\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
    "                                          shuffle=False, collate_fn=collate_fn_style_test,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:18:09.963863Z",
     "iopub.status.busy": "2021-10-24T21:18:09.963666Z",
     "iopub.status.idle": "2021-10-24T21:18:10.941541Z",
     "shell.execute_reply": "2021-10-24T21:18:10.940662Z",
     "shell.execute_reply.started": "2021-10-24T21:18:09.963839Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
    "                                                                        desc='Test',\n",
    "                                                                        position=1,\n",
    "                                                                        leave=None):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        position_ids = position_ids.to(device)\n",
    "\n",
    "        output = model(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       position_ids=position_ids,\n",
    "                       labels=labels)\n",
    "\n",
    "        logits = output.logits\n",
    "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
    "        predictions += batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:19:53.123809Z",
     "iopub.status.busy": "2021-10-24T21:19:53.123553Z",
     "iopub.status.idle": "2021-10-24T21:19:53.130545Z",
     "shell.execute_reply": "2021-10-24T21:19:53.129473Z",
     "shell.execute_reply.started": "2021-10-24T21:19:53.12378Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df['Category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T21:22:51.35152Z",
     "iopub.status.busy": "2021-10-24T21:22:51.351227Z",
     "iopub.status.idle": "2021-10-24T21:22:51.429885Z",
     "shell.execute_reply": "2021-10-24T21:22:51.428776Z",
     "shell.execute_reply.started": "2021-10-24T21:22:51.351442Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
