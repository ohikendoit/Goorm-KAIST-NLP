{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[HW5]Language_Model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jR26RFkwXtvi"},"source":["# **[HW5] Language Model**\n","1. DataLoader\n","2. Model\n","3. Trainer\n","4. Generation\n","\n","이번 실습에서는 RNN기반의 Language Model를 구현해서 텍스트를 직접 생성해보는 실습을 진행해보겠습니다.\n","\n","- dataset: WikiText2 (https://github.com/pytorch/examples/tree/master/word_language_model/data/wikitext-2)\n","- model: LSTM\n"]},{"cell_type":"markdown","metadata":{"id":"crVJ36mMlaXP"},"source":["\n","\n","## Import packages"]},{"cell_type":"markdown","metadata":{"id":"zpvlE_XOWS33"},"source":["런타임의 유형을 변경해줍니다.\n","\n","상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n","\n","변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"cqVdEuPQzMAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093318996,"user_tz":-540,"elapsed":250,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"671d445b-47f3-4976-8638-259a6dd8204d"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","print(torch.__version__)\n","print(torch.cuda.is_available())"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu102\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"2o3-HPdHLZma","executionInfo":{"status":"ok","timestamp":1631093319289,"user_tz":-540,"elapsed":14,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy as sp\n","import tqdm\n","import os\n","import random\n","import time\n","import datetime\n","\n","# for reproducibility\n","random.seed(1234)\n","np.random.seed(1234)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1GnKJCB4T_Q"},"source":["# 1. DataLoader\n","\n","이전의 실습들에서 사용한것과 마찬가지로, PyTorch style의 dataloader를 먼저 만들어 두겠습니다."]},{"cell_type":"markdown","metadata":{"id":"wcNl0aWbS0OA"},"source":["### Dataset\n","\n","저희가 이번 실습에서 사용할 데이터셋은 Wikipedia에 있는 영문 글들을 가져온 WikiTree dataset입니다.\n","저희가 불러올 데이터는 가장 작은 WikiTree dataset에서 자주 사용되지 않는 단어나 영어가 아닌 단어들은 <unk>으로 이미 전처리가 되어있습니다."]},{"cell_type":"code","metadata":{"id":"CKf8zNuISiC2","executionInfo":{"status":"ok","timestamp":1631093319833,"user_tz":-540,"elapsed":556,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["import urllib\n","with urllib.request.urlopen('https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/02-intermediate/language_model/data/train.txt') as f:\n","    data = f.readlines()"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBLNOlRKSpOI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093320453,"user_tz":-540,"elapsed":37,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"1a8562b1-7651-484d-abd6-9ea5384f376f"},"source":["print('num_sentence:',len(data))\n","data[100]"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["num_sentence: 42068\n"]},{"output_type":"execute_result","data":{"text/plain":["b\" plans that give advertisers discounts for maintaining or increasing ad spending have become permanent <unk> at the news <unk> and underscore the fierce competition between newsweek time warner inc. 's time magazine and <unk> b. <unk> 's u.s. news & world report \\n\""]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"OfLTv1EPbSwj","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1631093320456,"user_tz":-540,"elapsed":29,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"f63d2a52-d352-4042-8637-869afa4633fd"},"source":["seq_length_list = []\n","for line in data:\n","    seq_length_list.append(len(line.split()))\n","\n","counts, bins = np.histogram(seq_length_list, bins=20)\n","plt.hist(bins[:-1], bins, weights=counts)\n","plt.show()"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4SdattmOcRwC"},"source":["데이터에 있는 문장 길이들의 histogram을 볼 때 대부분의 data의 문장 길이가 50에 미치지 못하기 때문에 \\\\\n","model에 집어넣을 최대 문장 길이를 50으로 세팅해두도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"g7MuFqsKcd4U","executionInfo":{"status":"ok","timestamp":1631093320460,"user_tz":-540,"elapsed":23,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["max_seq_len = 50"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IyMpsyX8TwYy"},"source":["### Build Dictionary\n","\n","먼저 text 데이터를 모델에 넣어주기 위해서는 text에 존재하는 단어들을 index로 변환해주어야 합니다.\n","\n","이를 위해서는 단어를 index로 변환해주는 word2idx dictionary와 다시 index를 단어로 변환해주는 idx2word dictionary를 만들어야 합니다.\n"]},{"cell_type":"code","metadata":{"id":"cZmyZhcpTvZz","executionInfo":{"status":"ok","timestamp":1631093320707,"user_tz":-540,"elapsed":267,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["def build_dictionary(data, max_seq_len):\n","    word2idx = {}\n","    idx2word = {}\n","    ## Build Dictionary\n","    word2idx['<pad>'] = 0\n","    word2idx['<unk>'] = 1\n","    idx2word[0] = '<pad>'\n","    idx2word[1] = '<unk>'\n","    idx = 2\n","    for line in data:\n","        words = line.decode('utf-8').split()\n","        words = words[:max_seq_len]        \n","        ### Build Dictionary to convert word to index and index to word\n","        ### YOUR CODE HERE (~ 5 lines)\n","        for word in words:\n","          if word not in word2idx:\n","            word2idx[word] = idx\n","            idx2word[idx] = word\n","            idx += 1\n","    return word2idx, idx2word\n","\n","word2idx, idx2word = build_dictionary(data, max_seq_len)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPfV0OTc4Xdr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093320708,"user_tz":-540,"elapsed":16,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"514c3938-9fd3-4f85-e0ea-f3c070e16482"},"source":["if len(word2idx) == len(idx2word) == 10000:\n","    print(\"Test Passed!\")\n","else:\n","    raise AssertionError"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Passed!\n"]}]},{"cell_type":"markdown","metadata":{"id":"me_m8njoXHrv"},"source":["### Preprocessing\n","\n","이제 앞서 만든 dictionary를 이용해서 text로된 데이터셋을 index들로 변환시키겠습니다."]},{"cell_type":"code","metadata":{"id":"I6fuARgzXEDU","executionInfo":{"status":"ok","timestamp":1631093321074,"user_tz":-540,"elapsed":373,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["def preprocess(data, word2idx, idx2word, max_seq_len):\n","    tokens = []\n","    for line in data:\n","        words = line.decode('utf-8').split()\n","        words = words[:max_seq_len]\n","        ### Convert dataset with tokens\n","        ### For each line, append <pad> token to match the number of max_seq_len\n","        ### YOUR CODE HERE (~ 4 lines)\n","        words += ['<pad>']*(max_seq_len - len(words))\n","        for word in words:\n","          token = word2idx[word]\n","          tokens.append(token)\n","    return tokens\n","\n","tokens = preprocess(data, word2idx, idx2word, max_seq_len)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjyvqMgbZnfP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093321076,"user_tz":-540,"elapsed":25,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"bbe00c11-af1b-407c-ca8c-c200d29521bd"},"source":["if len(tokens) == 2103400:\n","    print(\"Test Passed!\")\n","else:\n","    raise AssertionError"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Passed!\n"]}]},{"cell_type":"markdown","metadata":{"id":"jmQxX3BH-SAv"},"source":["이제 전처리된 Token들을 문장 단위의 배열로 변환시켜 두겠습니다."]},{"cell_type":"code","metadata":{"id":"knMvtp23-Jye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093321078,"user_tz":-540,"elapsed":20,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"79161937-6da0-4b69-c313-557ea7445faa"},"source":["tokens = np.array(tokens).reshape(-1, max_seq_len)\n","print(tokens.shape)\n","tokens[100]"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["(42068, 50)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([745,  93, 746, 739, 747, 181, 748, 467, 749, 740, 750, 154, 751,\n","       752,   1, 160,  32, 753,   1,  48, 754,  32, 755, 756, 757, 728,\n","       555, 758,  99, 119, 555, 733,  48,   1, 759,   1, 119, 237, 753,\n","       230, 760, 347,   0,   0,   0,   0,   0,   0,   0,   0])"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"pceBqmtTZ9g9"},"source":["### DataLoader\n","\n","이제 전처리된 dataset을 활용하여 PyTorch style의 dataset과 dataloader를 만들도록 하겠습니다.\n","\n","Token형태의 데이터를 PyTorch 스타일의 dataset으로 만들 때 주의할 점은, 추후 embedding matrix에서 indexing을 해주기 위해서 각 token이 LongTensor 형태로 정의되어야 한다는 점입니다."]},{"cell_type":"code","metadata":{"id":"1hAwhG1K9iBI","executionInfo":{"status":"ok","timestamp":1631093321762,"user_tz":-540,"elapsed":54,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["class LMDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokens):\n","        super(LMDataset, self).__init__()\n","        self.PAD = 0\n","        self.UNK = 1\n","        self.tokens = tokens\n","        self._getitem(2)\n","\n","    def _getitem(self, index):\n","        X = self.tokens[index]\n","        y = np.concatenate((X[1:], [self.PAD]))\n","\n","        X = torch.from_numpy(X).unsqueeze(0).long()\n","        y = torch.from_numpy(y).unsqueeze(0).long()\n","\n","        return X, y\n","\n","    def __getitem__(self, index):\n","        X = self.tokens[index]\n","        y = np.concatenate((X[1:], [self.PAD]))\n","\n","        X = torch.from_numpy(X).long()\n","        y = torch.from_numpy(y).long()\n","\n","        return X, y\n","\n","    def __len__(self):\n","        return len(self.tokens)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiLNqM6kAda1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093321764,"user_tz":-540,"elapsed":54,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"bac23fb2-7e1b-44a3-bdd5-5ffcf83f4748"},"source":["batch_size = 64\n","dataset = LMDataset(tokens)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","print(len(dataset))\n","print(len(dataloader))"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["42068\n","658\n"]}]},{"cell_type":"markdown","metadata":{"id":"b1nhBnqWxw4a"},"source":["# 2. Model\n","\n","이번 section에서는 Language Modeling을 위한 Recurrent Model을 직접 만들어보도록 하겠습니다.\n","\n","Standard한 Recurrent Neural Network (RNN) model은 vanishing gradient 문제에 취약하기 때문에, 이번 실습에서는 변형된 RNN구조인 LSTM model을 활용하도록 하겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"aOoNVt3MDOjl"},"source":["### LSTM"]},{"cell_type":"markdown","metadata":{"id":"9lycT_9vwaJN"},"source":["LSTM model의 전체적인 구조와 각 gate의 수식은 아래와 같습니다.\n","\n","![](https://drive.google.com/uc?export=view&id=1n93tpNW55Xl4GxZNcJcbUVRhuNCGH38h)"]},{"cell_type":"markdown","metadata":{"id":"S1h6nfvYwN8n"},"source":["![](https://drive.google.com/uc?export=view&id=1nH9U5iD9cO6OVVTbrx-LjypRvcWzbOCU)\n","\n","LSTM의 자세한 동작방식이 궁금하신 분은 아래의 블로그를 참조해주세요.\n","\n","https://colah.github.io/posts/2015-08-Understanding-LSTMs/"]},{"cell_type":"code","metadata":{"id":"YDNAysVqxxOk","executionInfo":{"status":"ok","timestamp":1631093321766,"user_tz":-540,"elapsed":49,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["class LSTMCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMCell, self).__init__()\n","        # input-gate\n","        self.Wi = nn.Linear(input_size + hidden_size, hidden_size)\n","        # forget-gate\n","        self.Wf = nn.Linear(input_size + hidden_size, hidden_size)\n","        # gate-gate\n","        self.Wg = nn.Linear(input_size + hidden_size, hidden_size)\n","        # output-gate\n","        self.Wo = nn.Linear(input_size + hidden_size, hidden_size)\n","\n","        # non-linearity\n","        self.sigmoid = nn.Sigmoid()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x, h_0, c_0):\n","        \"\"\"\n","        Inputs\n","            input (x): [batch_size, input_size]\n","            hidden_state (h_0): [batch_size, hidden_size]\n","            cell_state (c_0): [batch_size, hidden_size]\n","        Outputs\n","            next_hidden_state (h_1): [batch_size, hidden_size]\n","            next_cell_state (c_1): [batch_size, hidden_size]    \n","        \"\"\"\n","        h_1, c_1 = None, None\n","        input = torch.cat((x, h_0), 1)\n","        # Implement LSTM cell as noted above\n","        ### YOUR CODE HERE (~ 6 lines)\n","        i = self.sigmoid(self.Wi(input))\n","        f = self.sigmoid(self.Wf(input))\n","        g = self.tanh(self.Wg(input))\n","        o = self.sigmoid(self.Wo(input))\n","        c_1 = f * c_0 + i * g\n","        h_1 = o * self.tanh(c_1)\n","        print(h_1, c_1)\n","        return h_1, c_1"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0Tff2VCJ56D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631093321767,"user_tz":-540,"elapsed":49,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"35a2f3ee-c781-4eee-a98c-1307b03191bd"},"source":["def test_lstm():\n","    batch_size = 2\n","    input_size = 5\n","    hidden_size = 3\n","\n","    #torch.manual_seed(1234)\n","    lstm = LSTMCell(input_size ,hidden_size)\n","    def init_weights(m):\n","        if isinstance(m, nn.Linear):\n","            torch.nn.init.constant_(m.weight, 0.1)\n","            m.bias.data.fill_(0.01)\n","    lstm.apply(init_weights)\n","\n","    x = torch.ones(batch_size, input_size)\n","    hx = torch.zeros(batch_size, hidden_size)\n","    cx = torch.zeros(batch_size, hidden_size)\n","\n","    hx, cx = lstm(x, hx, cx)\n","    assert hx.detach().allclose(torch.tensor([[0.1784, 0.1784, 0.1784], \n","                                              [0.1784, 0.1784, 0.1784]]), atol=2e-1), \\\n","            f\"Output of the hidden state does not match.\"\n","    assert cx.detach().allclose(torch.tensor([[0.2936, 0.2936, 0.2936], \n","                                              [0.2936, 0.2936, 0.2936]]), atol=2e-1), \\\n","            f\"Output of the cell state does not match.\"\n","\n","    print(\"==LSTM cell test passed!==\")\n","\n","test_lstm()"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1784, 0.1784, 0.1784],\n","        [0.1784, 0.1784, 0.1784]], grad_fn=<MulBackward0>) tensor([[0.2936, 0.2936, 0.2936],\n","        [0.2936, 0.2936, 0.2936]], grad_fn=<AddBackward0>)\n","==LSTM cell test passed!==\n"]}]},{"cell_type":"markdown","metadata":{"id":"0DxU-78B33dG"},"source":["## Language Model\n","\n","이제, 위에서 정의한 LSTM Cell을 활용해서 아래와 같은 Langauge Model을 만들어보도록 하겠습니다.\n","\n","\n","![](https://drive.google.com/uc?export=view&id=1nMAbL-g31nERM44dgohA3k9Vj_92hIh-)"]},{"cell_type":"code","metadata":{"id":"l0U2s0hux_n6","executionInfo":{"status":"ok","timestamp":1631093321768,"user_tz":-540,"elapsed":39,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["class LanguageModel(nn.Module):\n","    def __init__(self, input_size=64, hidden_size=64, vocab_size=10000):\n","        super(LanguageModel, self).__init__()\n","        \n","        self.input_layer = nn.Embedding(vocab_size, input_size)\n","        self.hidden_layer = LSTMCell(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, vocab_size)\n","\n","\n","    def forward(self, x, hx, cx, predict=False):\n","        \"\"\"\n","        Inputs\n","            input (x): [batch_size]\n","            hidden_state (h_0): [batch_size, hidden_size]\n","            cell_state (c_0): [batch_size, hidden_size]\n","            predict: whether to predict and sample the next word\n","        Outputs\n","            output (ox): [batch_size, hidden_size]\n","            next_hidden_state (h_1): [batch_size, hidden_size]\n","            next_cell_state (c_1): [batch_size, hidden_size]    \n","        \"\"\"\n","        x = self.input_layer(x)\n","        hx, cx = self.hidden_layer(x, hx, cx)\n","        ox = self.output_layer(hx)\n","\n","        if predict == True:\n","            probs = F.softmax(ox, dim=1)\n","            # torch distribution allows sampling operation\n","            # see https://pytorch.org/docs/stable/distributions.html\n","            dist = torch.distributions.Categorical(probs)\n","            ox = dist.sample()\n","\n","        return ox, hx, cx  "],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-ZpuMhsbBS8"},"source":["# 3. Trainer\n","\n","자 이제 위에서 구현한 dataloader와 langauge model을 활용해서 모델의 학습을 진행해보도록 하겠습니다.\n"]},{"cell_type":"code","metadata":{"id":"y7TY7HmvbRlB","executionInfo":{"status":"ok","timestamp":1631093321769,"user_tz":-540,"elapsed":39,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}}},"source":["class Trainer():\n","    def __init__(self, \n","                 word2idx, \n","                 idx2word,\n","                 dataloader, \n","                 model, \n","                 criterion,\n","                 optimizer, \n","                 device):\n","        \"\"\"\n","        dataloader: dataloader\n","        model: langauge model\n","        criterion: loss function to evaluate the model (e.g., BCE Loss)\n","        optimizer: optimizer for model\n","        \"\"\"\n","        self.word2idx = word2idx\n","        self.idx2word = idx2word\n","        self.dataloader = dataloader\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.device = device\n","        \n","    def train(self, epochs = 1):\n","        self.model.to(self.device)\n","        start_time = time.time()\n","        for epoch in range(epochs):\n","            losses = []\n","            for iter, (x_batch, y_batch) in tqdm.tqdm(enumerate(self.dataloader)):\n","                self.model.train()\n","                \n","                batch_size, max_seq_len = x_batch.shape\n","                x_batch = x_batch.to(self.device)\n","                y_batch = y_batch.to(self.device)\n","\n","                # initial hidden-states\n","                hx = torch.zeros(batch_size, hidden_size).to(self.device)\n","                cx = torch.zeros(batch_size, hidden_size).to(self.device)\n","\n","                # Implement LSTM operation\n","                ox_batch = []\n","                # Get output logits for each time sequence and append to the list, ox_batch\n","                # YOUR CODE HERE (~ 4 lines)\n","\n","\n","\n","                # outputs are ordered by the time sequence\n","                ox_batch = torch.cat(ox_batch).reshape(max_seq_len, batch_size, -1)\n","                ox_batch = ox_batch.permute(1,0,2).reshape(batch_size*max_seq_len, -1)\n","                y_batch = y_batch.reshape(-1)\n","\n","                self.model.zero_grad()\n","                loss = self.criterion(ox_batch, y_batch)\n","                loss.backward()\n","                self.optimizer.step()\n","                losses.append(loss.item())\n","\n","            end_time = time.time() - start_time\n","            end_time = str(datetime.timedelta(seconds=end_time))[:-7]\n","            print('Time [%s], Epoch [%d/%d], loss: %.4f'\n","                  % (end_time, epoch+1, epochs, np.mean(losses)))\n","            if epoch % 5 == 0:\n","                generated_sentences = self.test()\n","                print('[Generated Sentences]')\n","                for sentence in generated_sentences:\n","                    print(sentence)\n","            \n","    def test(self):\n","        # Test model to genereate the sentences\n","        self.model.eval()\n","        num_sentence = 5\n","        max_seq_len = 50\n","\n","        # initial hidden-states\n","        outs = []\n","        x = torch.randint(0, 10000, (num_sentence,)).to(self.device)\n","        hx = torch.zeros(num_sentence, hidden_size).to(self.device)\n","        cx = torch.zeros(num_sentence, hidden_size).to(self.device)\n","\n","        outs.append(x)\n","        with torch.no_grad():\n","            for s_idx in range(max_seq_len-1):\n","                x, hx, cx = self.model(x, hx, cx, predict=True)\n","                outs.append(x)\n","        outs = torch.cat(outs).reshape(max_seq_len, num_sentence)\n","        outs = outs.permute(1, 0)\n","        outs = outs.detach().cpu().numpy()\n","\n","        sentences = []\n","        for out in outs:\n","            sentence = []\n","            for token_idx in out:\n","                word = self.idx2word[token_idx]\n","                sentence.append(word)\n","            sentences.append(sentence)\n","       \n","        return sentences"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgEJv1vWqNkS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1631093322513,"user_tz":-540,"elapsed":781,"user":{"displayName":"hi choi","photoUrl":"","userId":"09784555200355646657"}},"outputId":"11dc49da-0cc9-4841-8c48-bc17820891ea"},"source":["lr = 1e-2\n","input_size = 128\n","hidden_size = 128\n","batch_size = 256\n","\n","dataset = LMDataset(tokens)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","model = LanguageModel(input_size=input_size, hidden_size=hidden_size)\n","# NOTE: you should use ignore_index to ignore the loss from predicting the <PAD> token\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","device = torch.device('cuda')\n","\n","trainer = Trainer(word2idx = word2idx,\n","                  idx2word = idx2word,\n","                  dataloader=dataloader, \n","                  model = model,\n","                  criterion=criterion,\n","                  optimizer = optimizer,\n","                  device=device)\n","\n","trainer.train(epochs=50)"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-ee6973909d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                   device=device)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-45-aed4c5dc60a8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# outputs are ordered by the time sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mox_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mox_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mox_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Named, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, UNKNOWN_TENSOR_TYPE_ID, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:16286 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:20674 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1025 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:60 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradMLC: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9928 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:9621 [kernel]\nAutocast: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:259 [kernel]\nBatched: registered at /pytorch/aten/src/ATen/BatchingRegistrations.cpp:1019 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"]}]},{"cell_type":"markdown","metadata":{"id":"nDhlrcENM4Dx"},"source":["생성된 텍스트의 퀄리티는 어떤가요? \n","\n","앞으로 딥러닝 강의가 끝나면 자연어처리 강좌에서 본격텍스트 처리에 적합한 전처리, 모델구조, 학습 trick들을 배우시게 될것입니다."]},{"cell_type":"markdown","metadata":{"id":"1Ua-_6W2a5Lt"},"source":["# References\n","\n","1. https://github.com/pytorch/examples/tree/master/word_language_model\n","2. https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model"]}]}