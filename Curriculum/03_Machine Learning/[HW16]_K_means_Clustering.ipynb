{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW16] K-means Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulhVcJFDgGDl"
      },
      "source": [
        "# [HW16] K-means Clustering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJY4o8idp0yO"
      },
      "source": [
        "##1. Introduction to K-Means Clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRiKMvL0mKpC"
      },
      "source": [
        "지금까지 저희는 input variable과 target variable이 있고, 이 둘 사이의 관계를 잘 설명해주는 model을 학습하는 과정을 배웠습니다. \n",
        "\n",
        "이처럼 target variable이 존재해서 우리가 정답(ground truth)를 알고 있고, 학습에 그것을 사용하는 것을 우리는 지도학습, supervised learning이라고 합니다. \n",
        "\n",
        "앞서 실습에서 했던 예시로 알아보면, 우리는 부품의 사진을 보고 그 부품에 결함이 있는지 없는지 알 수 있었고, 그 사실을 학습에 사용했습니다. 이것을 우리는 지도학습이라고 부릅니다. \n",
        "\n",
        "하지만 우리가 target variable을 모른다면 어떻게 될까요? 이번 시간에는 우리는 ground truth를 모르고, 사용하지 않은 채로 학습을 하는 비지도학습, unsupervised learning의 알고리즘 중 하나인 **k-means clustering**에 대해서 알아보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clu5kOFerGQi"
      },
      "source": [
        "K-means clustering은 분류가 되어있지 않은 데이터들을 다룰 때 사용합니다. 미리 정해놓은 개수(K)의 클러스터로 주어진 데이터를 묶어내는 방법론입니다. 주어진 데이터들을 반복적으로 K개의 클러스터 중 하나로 할당하는 방법으로 학습이 진행됩니다. 결국 가까운 데이터들 끼리 같은 클러스터에 할당되게 됩니다. 이미지로 나타내면 다음과 같습니다. \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2160/1*tWaaZX75oumVwBMcKN-eHA.png\n",
        "\" width=\"700\" height=\"300\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7qFPhyrs96x"
      },
      "source": [
        "## 2. K-Means clustering intuition\n",
        "\n",
        "K-Means clustering은 레이블이 지정되지 않은 데이터를 중심부(centroid)를 기반으로 clustering 을 합니다. \n",
        "\n",
        "이 때 중심부는 각 cluster 의 중심을 의미합니다. K-Means clustering은 다음 2가지 step을 반복적으로 수행하면서 이루어집니다. \n",
        "\n",
        "1. Data assignment step\n",
        "각 centroid는 하나의 cluster를 의미합니다. 모든 데이터들은 각자 자신과 가장 가까운 centroid에 해당하는 cluster에 속하게 됩니다. \n",
        "\n",
        "2. Centroid update step\n",
        "각 data가 cluster에 배정이 되었다면, 이제 cluster에 속해 있는 data들의 평균 위치로 centroid가 다시 갱신됩니다. \n",
        "\n",
        "더이상 data들의 cluster가 변하지 않을 때까지 이 두가지 과정을 반복적으로 수행하게 됩니다. 이 알고리즘은 반드시 수렴하게 되어있지만 초기화 하는 방식에 따라서 local optimum으로 수렴하게 될 수도 있습니다. K-Means clustering의 과정을 그림으로 보겠습니다. \n",
        "\n",
        "<img src=\"https://i.ytimg.com/vi/_aWzGGNrcic/hqdefault.jpg\n",
        "\" width=\"600\" height=\"450\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkome2zOQ5t1"
      },
      "source": [
        "## 3. Choosing the value of K\n",
        "\n",
        "K-Means algorithm은 우리가 미리 정해놓은 K에 값에 따라서 작동하게 됩니다. 그래서 우리는 가장 좋은 K의 값을 찾기 위해 여러가지 K 값으로 알고리즘을 수행해 보고 비교를 통해서 찾아야 합니다. \n",
        "\n",
        "가장 좋은 K값을 찾는데에는 여러가지 방법이 있지만 이번 실습에서는 가장 대표적인 **elbow method**를 사용해 보겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWP8cWypRbTH"
      },
      "source": [
        "## 4. The elbow method\n",
        "\n",
        "The elbow method는 가장 좋은 K 값을 찾는데 사용하는 방법입니다. 여러가지 K에 대해서 모두 실험을 해보고 해당 cost function을 그래프로 표현한 뒤 최적의 K 값을 찾습니다. \n",
        "\n",
        "예시 그래프를 보도록 하겠습니다. \n",
        "\n",
        "<img src=\"https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/995b8b58-06f1-4884-a2a1-f3648428e947.png\n",
        "\" width=\"700\" height=\"400\" />\n",
        "\n",
        "K가 커질수록 cost function이 줄어듭니다. 그러나 무작정 K의 개수를 키운다면 그것은 clustering 을 하는 의미가 없어집니다. 그래서 cost function이 가장 가파르게 줄어드는 마지막 지점의 K를 선택을 하게 되고 이것이 elbow method 입니다. \n",
        "\n",
        "이제부터는 직접 data를 가져와서 진행해보도록 하겠습니다! \n",
        "\n",
        "Dataset에 자세한 설명은 아래 링크에 나와있습니다. \n",
        "\n",
        "https://www.kaggle.com/uciml/iris\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqLYlYjoxUhN"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "URL = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
        "urlretrieve(URL, 'Iris.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz579npYgDYr"
      },
      "source": [
        "#importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing the Iris dataset with pandas\n",
        "dataset = pd.read_csv('/content/Iris.csv')\n",
        "x = dataset.iloc[:, [0, 1, 2, 3]].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWmTbgHyPPE"
      },
      "source": [
        "dataset.info()\n",
        "dataset[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAdFkfkKcBKD"
      },
      "source": [
        "이제 scikit-learn 속의 Kmeans 패키지를 이용해서 진행해보겠습니다.  \n",
        "\n",
        "K개수를 1부터 10까지 진행해보면서 cost function인 inertia를 측정해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmN16wqzbzWu"
      },
      "source": [
        "#Finding the optimum number of clusters for k-means classification\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
        "    kmeans.fit(x)\n",
        "    wcss.append(kmeans.inertia_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89QaSxDfoiP"
      },
      "source": [
        "The elbow method를 사용하기 위해서 그래프를 찍어보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMuTkNn4fbo6"
      },
      "source": [
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('The elbow method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS') #within cluster sum of squares\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpGcM6FZfvFg"
      },
      "source": [
        "K를 3으로 설정을 해서 K-Means 를 수행한 뒤 결과를 보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCc6UzDfrph"
      },
      "source": [
        "kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
        "y_kmeans = kmeans.fit_predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULmKRTccf1cW"
      },
      "source": [
        "#Visualising the clusters\n",
        "plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'purple', label = 'Iris-setosa')\n",
        "plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'orange', label = 'Iris-versicolour')\n",
        "plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')\n",
        "\n",
        "#Plotting the centroids of the clusters\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'red', label = 'Centroids')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRfJbKMmf2lw"
      },
      "source": [
        "# 3d scatterplot using matplotlib\n",
        "\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'purple', label = 'Iris-setosa')\n",
        "plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'orange', label = 'Iris-versicolour')\n",
        "plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')\n",
        "\n",
        "#Plotting the centroids of the clusters\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'red', label = 'Centroids')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBk2UUX6gH__"
      },
      "source": [
        "오늘은 unsupervised learning 중 하나인 K-Means clustering에 대해서 알아보았습니다. \n",
        "\n",
        "다음 시간에는 Neural Network에 대해서 알아보도록 하겠습니다. \n",
        "\n",
        "질문 있으면 편하게 해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpcuVB8Vf4Fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}