{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[HW6]DCGAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jR26RFkwXtvi"},"source":["# **[HW6] DCGAN**\n","1. DataLoader\n","2. Model\n","3. Inception Score\n","4. Trainer\n","5. Train\n","\n","이번 실습에서는 Convolution기반의 Generative Adversarial Network를 구현해서 이미지를 직접 생성해보는 실습을 진행해보겠습니다.\n","\n","- dataset: CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n","- model: DCGAN (https://arxiv.org/abs/1511.06434)\n","- evaluation: Inception Score (https://arxiv.org/abs/1801.01973)"]},{"cell_type":"markdown","metadata":{"id":"crVJ36mMlaXP"},"source":["\n","\n","## Import packages"]},{"cell_type":"markdown","metadata":{"id":"zpvlE_XOWS33"},"source":["런타임의 유형을 변경해줍니다.\n","\n","상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n","\n","변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"cqVdEuPQzMAH"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","print(torch.__version__)\n","print(torch.cuda.is_available())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2o3-HPdHLZma"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy as sp\n","import tqdm\n","import os\n","import random\n","import time\n","import datetime\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","\n","# for reproducibility\n","np.set_printoptions(precision=3)\n","np.set_printoptions(suppress=True)\n","random.seed(1234)\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1GnKJCB4T_Q"},"source":["# 1. DataLoader\n","\n","이전의 실습들에서 사용한것과 마찬가지로, pre-defined된 CIFAR-10 dataset을 활용해서 dataloader를 만들어 두겠습니다."]},{"cell_type":"code","metadata":{"id":"EPfV0OTc4Xdr"},"source":["from PIL import Image\n","from torch.utils import data\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","def create_dataloader(batch_size=64, num_workers=1):\n","    transform = transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./data/', train=True, transform=transform, download=True)\n","    testset = torchvision.datasets.CIFAR10(root='./data/', train=False, transform=transform, download=True)\n","\n","    trainloader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","    testloader = data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","    return trainloader, testloader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1nhBnqWxw4a"},"source":["# 2. Model\n","\n","이번 section에서는 DCGAN의 모델구조를 직접 구현해보도록 하겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"9lycT_9vwaJN"},"source":["우선 본격적인 모델 구현에 앞서 GAN의 전체적인 구조에 대해 살펴보겠습니다.\n","\n","GAN은 Generator와 Discriminator로 구성되어, Generator는 random latent vector를 받아 Discriminator를 속일 수 있는 fake image를 만들고, Discriminator는 real image와 fake image를 구분하는 형태로 학습이 진행되게 됩니다.\n","\n","![](https://drive.google.com/uc?export=view&id=1mydINGwCR9maUffL-ejlT8vOPjWM5cYj)"]},{"cell_type":"markdown","metadata":{"id":"S1h6nfvYwN8n"},"source":["DCGAN은 image 데이터 처리에 효과적인 convolution layer를 활용하여 Generator와 Discriminator의 구조를 변형한 모델입니다.\n","\n","DCGAN의 Generator와 Discriminator의 구조는 아래와 같습니다.\n","\n","![](https://drive.google.com/uc?export=view&id=1mp8jgDC5CDoZQNSGnq3kQRwSNQA7TIXl)\n","\n","\n","이 때, Generator는 output의 width와 height를 키우는 convolution을 진행해주어야 하기 때문에, standard한 convolution operation이 아닌 deconvolution 혹은 transpose convolution이라고 불리는 연산을 통해 output의 size를 키워주는 연산을 진행하게 됩니다.\n","\n","![](https://drive.google.com/uc?export=view&id=1mqoDvM3a4qnnu9IH60isrXtN7-RB_vgD)\n","\n","반대로, Discriminator는 Generator와 대칭되는 구조를 통해 standard한 convolution을 사용하여 classification을 진행해주게 됩니다.\n","\n","Transpose Convolution:(https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)\n"]},{"cell_type":"markdown","metadata":{"id":"q4t4Un1o2KVH"},"source":["## Convolution Block\n","\n","우선, 모델을 쉽게 구현할 수 있도록, Generator와 Discriminator에서 반복적으로 사용할 convolution block고 deconvolution block을 정의해두도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"ssBO9DfqagW8"},"source":["def conv(c_in, c_out, k_size, stride=2, pad=1, bias=False, norm='bn', activation=None):\n","    layers = []\n","\n","    # Conv.\n","    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=bias))\n","\n","    # Normalization\n","    if norm == 'bn':\n","        layers.append(nn.BatchNorm2d(c_out))\n","    elif norm == None:\n","        pass\n","\n","    # Activation\n","    if activation == 'lrelu':\n","        layers.append(nn.LeakyReLU(0.2))\n","    elif activation == 'relu':\n","        layers.append(nn.ReLU())\n","    elif activation == 'tanh':\n","        layers.append(nn.Tanh())\n","    elif activation == 'sigmoid':\n","        layers.append(nn.Sigmoid())\n","    elif activation == None:\n","        pass\n","\n","    return nn.Sequential(*layers)\n","\n","\n","def deconv(c_in, c_out, k_size, stride=2, pad=1, output_padding=0, bias=False, norm='bn', activation=None):\n","    layers = []\n","\n","    # Deconv.\n","    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, output_padding, bias=bias))\n","\n","    # Normalization\n","    if norm == 'bn':\n","        layers.append(nn.BatchNorm2d(c_out))\n","    elif norm == None:\n","        pass\n","\n","    # Activation\n","    if activation == 'lrelu':\n","        layers.append(nn.LeakyReLU(0.2))\n","    elif activation == 'relu':\n","        layers.append(nn.ReLU())\n","    elif activation == 'tanh':\n","        layers.append(nn.Tanh())\n","    elif activation == 'sigmoid':\n","        layers.append(nn.Sigmoid())\n","    elif activation == None:\n","        pass\n","\n","    return nn.Sequential(*layers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYR2fBMM2kXM"},"source":["## Generator\n","\n","이제, 위에서 정의한 deconv block을 활용해서 DCGAN의 Generator를 구현해보도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"YDNAysVqxxOk"},"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        model = []\n","\n","        ### DCGAN Generator\n","        # You have to implement 4-layers generator.\n","        # Note: Recommend to use 'deconv' function\n","        ### YOUR CODE HERE (~ 4 lines)\n","\n","\n","\n","        ### END YOUR CODE\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, z):\n","        # Input (z) size : [Batch, 256, 1, 1]\n","        # Output (Image) size : [Batch, 3, 32, 32]\n","        z = z.view(z.size(0), z.size(1), 1, 1)\n","        output = self.model(z)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0DxU-78B33dG"},"source":["## Discriminator\n","\n","이제, 위에서 정의한 conv block을 활용해서 DCGAN의 Discriminator를 구현해보도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"l0U2s0hux_n6"},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        model = []\n","\n","        ### DCGAN Discriminator\n","        # You have to implement 4-layers discriminator.\n","        # Note: Recommend to use 'conv' function \n","        ### YOUR CODE HERE (~ 4 lines)\n","\n","\n","\n","        ### END YOUR CODE\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x: torch.Tensor):\n","        # Input (z) size : [Batch, 3, 32, 32]\n","        # Output (probability) size : [Batch, 1]\n","        output = self.model(x).squeeze()\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W68n93Mb6aMi"},"source":["## Implementation Test\n","\n","이제 Generator와 Discriminator를 맞게 구현했는지 test해보도록 하겠습니다.\n","\n","체크를 위해서 코드와 함께 주어졌던 두개의 파일\n","- sanity_check_dcgan_netG.pth\n","- sanity_check_dcgan_netD.pth\n","\n","를 왼쪽 상단에 [파일]->[세션 저장소에 업로드]를 눌러 업로드 하고, \\\\\n","아래의 코드를 실행시켜 코드가 통과되면 성공입니다. "]},{"cell_type":"code","metadata":{"id":"G8SnkmI95Tvw"},"source":["def test_model():\n","    print(\"=====Model Initializer Test Case======\")\n","    netG = Generator()\n","    # the first test\n","    try:\n","        netG.load_state_dict(torch.load(\"sanity_check_dcgan_netG.pth\", map_location='cpu'))\n","    except Exception as e:\n","        print(\"Your DCGAN generator initializer is wrong. Check the comments in details and implement the model precisely.\")\n","        raise e\n","    print(\"The first test passed!\")\n","\n","    # the second test\n","    netD = Discriminator()\n","    try:\n","        netD.load_state_dict(torch.load(\"sanity_check_dcgan_netD.pth\", map_location='cpu'))\n","    except Exception as e:\n","        print(\"Your DCGAN discriminator initializer is wrong. Check the comments in details and implement the model precisely.\")\n","        raise e\n","    print(\"The second test passed!\")\n","    print(\"All 2 tests passed!\")\n","\n","test_model()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36LwdYMDatum"},"source":["# 3. Inception Score\n","\n","비록 이제 dataloader와 model을 구현하였지만, 본격적으로 학습을 진행하기전 지도학습과 다르게 한가지 추가적으로 필요한 것이 있습니다.\n","\n","기존의 지도학습 세팅에서는 loss나 validation accuracy를 통해서 학습이 원활히 진행되고 있는지 모니터링이 가능했지만, GAN에서는 generator가 비록 discriminator를 잘 속이고 있을지라도 (i.e., 낮은 loss) discriminator가 학습이 충분히 되지 못했다면 낮은 퀄리티의 이미지가 생성되게 됩니다.\n","\n","이미지의 퀄리티를 측정하는 방법은 크게 2가지 입니다.\n","1. Fidelity(충실도): 얼마나 고품질의 이미지를 생성하는가?.\n","2. Diversity(다양성): 생성된 이미지들이 얼마나 다양한가? (e.g., 고양이만 생성하지 않음)\n","\n","보통 Fidelity를 측정하기 위해서는 **Frechet Inception Distance**라는 metric이, Diversity를 측정하기 위해서는 **Inception Score**라는 evaluation metric이 사용되곤 합니다.\n","\n","이번 실습에서는 이미지의 다양성을 측정하는 Inception Score를 통해 학습이 원활히 진행되고 있는지 모니터링 하도록 하겠습니다.\n","\n","Inception score를 측정하는 방법은 아래와 같습니다.\n","1. Generator를 통해 이미지를 N개 생성한다.\n","2. 생성된 이미지들을 pre-trained된 inception network (=googleNet)에 통과시킨다.\n","3. inception network가 예측한 생성된 image의 label별 probability의 평균이 얼마나 diverse한지 측정한다.\n","\n","Inception score에 대한 자세한 내용이 궁금하신 분은 아래를 참조해주세요\n","- https://arxiv.org/abs/1801.01973\n","- https://cyc1am3n.github.io/2020/03/01/is_fid.html\n"]},{"cell_type":"code","metadata":{"id":"6QRDNecSHTLz"},"source":["from torchvision.models.inception import inception_v3\n","from scipy.stats import entropy\n","\n","class Inception_Score():\n","    def __init__(self, dataset):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        # Dataset & DataLoader\n","        self.N = len(dataset)\n","        self.batch_size = 64\n","\n","        self.dataset = dataset\n","        self.dataloader = data.DataLoader(dataset=dataset, batch_size=self.batch_size, num_workers=1)\n","        self.transform = nn.Upsample(size=(299, 299), mode='bilinear').to(self.device)\n","\n","        # Inception Model\n","        self.inception_model = inception_v3(pretrained=True, transform_input=False).to(self.device)\n","        self.inception_model.eval()\n","\n","    def get_pred(self, x):\n","        with torch.no_grad():\n","            x = self.transform(x)\n","            x = self.inception_model(x)\n","            return F.softmax(x, dim=1).data.cpu().numpy()\n","\n","    def compute_score(self, splits=1):\n","        preds = np.zeros((self.N, 1000))\n","\n","        for i, batch in tqdm.tqdm(enumerate(self.dataloader)):\n","            batch = batch.to(self.device)\n","            batch_size_i = batch.size(0)\n","            preds[i * self.batch_size : i * self.batch_size + batch_size_i] = self.get_pred(batch)\n","\n","        # Compute the mean KL-divergence\n","        # You have to calculate the inception score.\n","        # The logit values from inception model are already stored in 'preds'.\n","        inception_score = 0.0\n","        split_scores = []\n","        for k in tqdm.tqdm(range(splits)):\n","            part = preds[k * (self.N // splits): (k + 1) * (self.N // splits), :]\n","            py = np.mean(part, axis=0)\n","            scores = []\n","            for i in range(part.shape[0]):\n","                pyx = part[i, :]\n","                scores.append(entropy(pyx, py))\n","            split_scores.append(np.exp(np.mean(scores)))\n","        inception_score = np.mean(split_scores)\n","\n","        return inception_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtzK6bKsHfaj"},"source":["def test_inception_score():\n","    print(\"======Inception Score Test Case======\")\n","\n","    # CIFAR10 Datset without Label\n","    class CIFAR10woLabel():\n","        def __init__(self):\n","            transform = transforms.Compose([transforms.ToTensor(),\n","                                            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n","            self.dataset = torchvision.datasets.CIFAR10(root='./data/', download=True, transform=transform)\n","\n","        def __getitem__(self, index):\n","            return self.dataset[index][0]\n","\n","        def __len__(self):\n","            return len(self.dataset)\n","\n","    print(\"Calculating Inception Score...\")\n","\n","    Inception = Inception_Score(CIFAR10woLabel())\n","    score = Inception.compute_score(splits=1)\n","\n","    assert np.allclose(score, 9.719672, atol=1e-3), \\\n","        \"Your inception score does not match expected result.\"\n","\n","    print(\"All test passed!\")\n","\n","test_inception_score()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xa2ZABccII_K"},"source":["# 4. Trainer\n","\n","이제 앞서 선언한 dataloader, model, evaluator를 모두 활용해서 GAN을 학습시키는 Trainer를 구현해보도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"U2PIMmgCYQU7"},"source":["## Preliminary\n","\n","\\begin{equation}\n","D_{\\theta}: \\text{Discriminator network}\\\\\n","G_{\\phi}: \\text{Generator network}\\\\\n","x: \\text{real_image} \\\\\n","z: \\text{latent_vector} \\\\\n","\\end{equation}\n"]},{"cell_type":"markdown","metadata":{"id":"18SBMREkcjZh"},"source":["## Discriminator Loss\n","\n","\\begin{equation}\n","\\mathcal{L}_{D_{\\theta}} = -E_{x \\sim p_{data}}[logD_{\\theta}(x) + E_{z}[\\log(1 - D_{\\theta}(G_{\\phi}(z)))]]\n","\\end{equation}\n","\n","Discriminator loss는 위와 같이 real_image는 1으로, generated_image는 0으로 판별하는 방식으로 학습을 진행하게 됩니다. "]},{"cell_type":"markdown","metadata":{"id":"VIHlU8M0cpPy"},"source":["## Generator Loss\n","\n","Generator network는 이론적으로는 discriminator의 loss에서 generator가 해당되는 부분에 -1을 곱해서 표현할 수 있습니다.\n","\n","\\begin{equation}\n","\\mathcal{L}_{G_{\\phi}} = E_{z}[\\log(1-D_{\\theta}(G_{\\phi}(z))]  \\tag{1}\n","\\end{equation}\n","\n","하지만, 위의 식으로 학습을 진행할 경우 Generator의 학습이 원활히 이루어지지 않게되는 문제점이 있습니다.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"I0ImQBI_8oEr"},"source":["plt.title('log(1-D(G(z))')\n","x = np.arange(0, 1.0, 0.01)\n","y = np.log(1-x)\n","plt.xlabel('D(G(z))')\n","plt.plot(x,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dnx579Fk9jBr"},"source":["위의 loss plot에서 볼 수 있듯이, Generator는 Discriminator를 속이는 것에 성공할 수록 $D_{\\theta}(G_{\\phi}(z)) \\approx 1$ 낮은 loss를 갖게 됩니다. \n","\n","하지만, 이미지 생성의 난이도를 생각하면, 학습 초반에 Discriminator에 비해 Generator가 못하는 일은 자명한 일입니다. 이 때, D(G(z))가 0에 가까운 지점 $D_{\\theta}(G_{\\phi}(z)) \\approx 0$ 에서의 함수의 기울기가 너무 작기 때문에 학습 초반에 Generator가 충분한 양의 학습 시그널을 받지 못하게 되는 문제점이 발생하게 됩니다.\n","\n","따라서, 위의 식과 직관적으로 유사한 의미를 가지는 다른 loss function을 정의해보도록 하겠습니다.\n","\n","\\begin{equation}\n","\\mathcal{L}_{G_{\\phi}} = -E_{z}[\\log(D_{\\theta}(G_{\\phi}(z))]  \\tag{2}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"id":"JLoGHehfhjuo"},"source":["plt.title('-log(D(G(z))')\n","x = np.arange(0, 1.0, 0.01)\n","y = -np.log(x)\n","plt.xlabel('D(G(z))')\n","plt.plot(x,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ha3rIQ2i_NiN"},"source":["위의 loss plot에서 볼 수 있듯이, Generator는 여전히 Discriminator를 속이는 것에 성공할 수록 $D_{\\theta}(G_{\\phi}(z)) \\approx 1$ 낮은 loss를 갖게 됩니다. \n","\n","하지만, 이전과는 달리 $D_{\\theta}(G_{\\phi}(z)) \\approx 0$에서의 gradient가 크기 때문에 학습 초반에 이미지를 생성하지 못할 때 오히려 충분한 양의 학습 시그널을 받을 수 있게 됩니다.\n","\n","따라서, 이번 과제에서는 Generator의 Loss로 두번째 식을 사용하도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"oojglLhdKf6m"},"source":["# Utility Functions\n","def denorm(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)\n","\n","def save_checkpoint(model, save_path, device):\n","    if not os.path.exists(os.path.dirname(save_path)):\n","        os.makedirs(os.path.dirname(save_path))\n","    torch.save(model.cpu().state_dict(), save_path)\n","    model.to(device)\n","\n","def load_checkpoint(model, checkpoint_path, device):\n","    if not os.path.exists(checkpoint_path):\n","        print(\"Invalid path!\")\n","        return\n","    model.load_state_dict(torch.load(checkpoint_path))\n","    model.to(device)\n","\n","class FolderDataset(data.Dataset):\n","    def __init__(self, folder):\n","        self.folder = folder\n","        self.image_list = os.listdir(folder)\n","        self.transform = transforms.Compose([transforms.ToTensor(),\n","                                             transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n","\n","    def __getitem__(self, index):\n","        image = Image.open(os.path.join(self.folder, self.image_list[index]))\n","        return self.transform(image)\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","\n","# Trainer\n","class Trainer():\n","    def __init__(self, \n","                 trainloader, \n","                 testloader, \n","                 generator, \n","                 discriminator, \n","                 criterion,\n","                 g_optimizer, \n","                 d_optimizer, \n","                 device):\n","        \"\"\"\n","        trainloader: train data's loader\n","        testloader: test data's loader\n","        generator: generator\n","        discriminator: discriminator\n","        criterion: loss function to evaluate the model (e.g., BCE Loss)\n","        g_optimizer: optimizer for generator\n","        d_optimizer: optimizer for discriminator\n","        \"\"\"\n","        self.trainloader = trainloader\n","        self.testloader = testloader\n","        self.G = generator\n","        self.D = discriminator\n","        self.criterion = criterion\n","        self.g_optimizer = g_optimizer\n","        self.d_optimizer = d_optimizer\n","        self.device = device\n","\n","        # Make directory to save the images & models for a specific checkpoint\n","        os.makedirs(os.path.join('./results/', 'images'), exist_ok=True)\n","        os.makedirs(os.path.join('./results/', 'checkpoints'), exist_ok=True)\n","        os.makedirs(os.path.join('./results/', 'evaluation'), exist_ok=True)\n","        \n","    def train(self, epochs = 1):\n","        self.G.to(self.device)\n","        self.D.to(self.device)\n","\n","        start_time = time.time()\n","        for epoch in range(epochs):\n","            for iter, (real_img, _) in enumerate(self.trainloader):\n","                self.G.train()\n","                self.D.train()\n","                \n","                batch_size = real_img.size(0)\n","                real_label = torch.ones(batch_size).to(self.device)\n","                fake_label = torch.zeros(batch_size).to(self.device)\n","                # get real CIFAR-10 image\n","                real_img = real_img.to(self.device)\n","                # initialize latent_vector to feed into the Generator\n","                z = torch.randn(real_img.size(0), 256).to(self.device)\n","\n","                ##########################################################################################\n","                # Discriminator Loss 구현                                                                #\n","                # Note : Discriminator Loss는 Generator network의 parameter에 영향을 주지 않아야 합니다. #\n","                #        detach() function을 참고하세요.                                                 #\n","                #        https://pytorch.org/docs/stable/generated/torch.Tensor.detach.html              #\n","                ##########################################################################################\n","                D_loss: torch.Tensor = None\n","                ### YOUR CODE HERE (~ 4 lines)\n","\n","\n","\n","                ### END YOUR CODE\n","\n","                # TEST CODE\n","                # (TEST의 통과가 맞는 구현을 보장하지는 못합니다. 일반적으로는 loss가 1.38~1.45 사이의 값이 나와야 합니다.)\n","                if epoch == 0 and iter == 0:\n","                    assert D_loss.detach().allclose(torch.tensor(1.4000), atol=2e-1), \\\n","                    f\"Discriminator Loss of the model does not match expected result.\"\n","                    print(\"==Discriminator loss function test passed!==\")\n","\n","                self.D.zero_grad()\n","                D_loss.backward()\n","                self.d_optimizer.step()\n","\n","                #######################################################\n","                # Generator Loss 구현                                 #\n","                # Note : 위의 정의된 두번 째 식을 사용해서 구현하세요 #\n","                #######################################################\n","                G_loss: torch.Tensor = None\n","                ### YOUR CODE HERE (~ 3 lines)\n","\n","\n","\n","                ### END YOUR CODE\n","\n","                # Test code\n","                # (TEST의 통과가 맞는 구현을 보장하지는 못합니다. 일반적으로는 loss가 1.35~1.52 사이의 값이 나와야 합니다.)\n","                if epoch == 0 and iter == 0:\n","                    assert G_loss.detach().allclose(torch.tensor(1.5), atol=2e-1), \\\n","                    f\"Generator Loss of the model does not match expected result.\"\n","                    print(\"==Generator loss function test passed!==\")\n","\n","                self.G.zero_grad()\n","                G_loss.backward()\n","                self.g_optimizer.step()\n","\n","            # verbose\n","            end_time = time.time() - start_time\n","            end_time = str(datetime.timedelta(seconds=end_time))[:-7]\n","            print('Time [%s], Epoch [%d/%d], lossD: %.4f, lossG: %.4f'\n","                  % (end_time, epoch+1, epochs, D_loss.item(), G_loss.item()))\n","\n","            # Save Images\n","            fake_img = fake_img.reshape(fake_img.size(0), 3, 32, 32)\n","            torchvision.utils.save_image(denorm(fake_img), os.path.join('./results/', 'images', 'fake_image-{:03d}.png'.format(epoch+1)))\n","            if epoch % 10 == 0:\n","                self.test()\n","\n","        # Save Checkpoints\n","        save_checkpoint(self.G, os.path.join('./results', 'checkpoints', 'G_final.pth'), self.device)\n","        save_checkpoint(self.D, os.path.join('./results', 'checkpoints', 'D_final.pth'), self.device)\n","\n","    def test(self):\n","        print('Start computing Inception Score')\n","        self.G.eval()\n","        with torch.no_grad():\n","            for iter in tqdm.tqdm(range(5000)):\n","                z = torch.randn(1, 256).to(self.device)\n","                fake_img = self.G(z)\n","                torchvision.utils.save_image(denorm(fake_img), os.path.join('./results/', 'evaluation', 'fake_image-{:03d}.png'.format(iter)))\n","\n","        # Compute the Inception score\n","        dataset = FolderDataset(folder = os.path.join('./results/', 'evaluation'))\n","        Inception = Inception_Score(dataset)\n","        score = Inception.compute_score(splits=1)\n","        print('Inception Score : ', score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKACzMg9SzDF"},"source":["### Train\n","\n","자, 이제 학습을 진행해 보겠습니다.\n","학습이 진행됨에 따라 generator가 생성하는 image는 \\\\\n","[파일]->[results]->[images]에서 각 epoch별로 확인해보실 수 있습니다."]},{"cell_type":"code","metadata":{"id":"pBuw5xCdIglG"},"source":["lr = 2e-4\n","\n","trainloader, testloader = create_dataloader()\n","G = Generator()\n","D = Discriminator()\n","criterion = nn.BCELoss()\n","g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n","d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n","device = torch.device('cuda')\n","\n","trainer = Trainer(trainloader=trainloader, \n","                  testloader=testloader,\n","                  generator=G,\n","                  discriminator=D,\n","                  criterion=criterion,\n","                  g_optimizer=g_optimizer,\n","                  d_optimizer=d_optimizer,\n","                  device=device)\n","\n","trainer.train(epochs=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Y2faWkGQ5WG"},"source":[""],"execution_count":null,"outputs":[]}]}