{"cells":[{"cell_type":"markdown","metadata":{"id":"jR26RFkwXtvi"},"source":["# **[HW2] Training Neural Network**\n","1. Prerequisite\n","2. Activation\n","3. Optimizer\n","4. Regularization\n","5. FC vs Conv\n","6. Do it by yourself\n","\n","이번 실습에서는 지난 시간에 배웠던 MLP-layer의 component들을 하나씩 바꿔가며 activation, optimizer, regularization, convolution layer등의 중요성을 하나씩 익혀가는 시간을 갖도록 하겠습니다.  "]},{"cell_type":"markdown","metadata":{"id":"xp3f6JjmmlC3"},"source":["# 1. Prerequisite\n","\n","본격적인 실습을 진행하기 이전, 지난 [HW1.2 Logistic Regression vs MLP]에서 진행했던것과 동일하게 \\\\\n","Mnist dataset에 대해서 DataLoader와 Trainer class를 생성해두겠습니다."]},{"cell_type":"markdown","metadata":{"id":"crVJ36mMlaXP"},"source":["\n","\n","## Import packages"]},{"cell_type":"markdown","metadata":{"id":"zpvlE_XOWS33"},"source":["런타임의 유형을 변경해줍니다.\n","\n","상단 메뉴에서 [런타임]-\u003e[런타임유형변경]-\u003e[하드웨어가속기]-\u003e[GPU]\n","\n","변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4916,"status":"ok","timestamp":1631149364611,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"},"user_tz":-540},"id":"cqVdEuPQzMAH","outputId":"9e5b5217-402f-4f89-bdd3-d9ec53aa72c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.9.0+cu102\n","False\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","from torch.utils import data\n","print(torch.__version__)\n","print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1302,"status":"ok","timestamp":1631149365907,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"},"user_tz":-540},"id":"2o3-HPdHLZma"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy as sp\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","\n","np.set_printoptions(precision=3)\n","np.set_printoptions(suppress=True)"]},{"cell_type":"markdown","metadata":{"id":"nMkIJgfEl9kD"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCnmrA9ltYs0"},"outputs":[],"source":["mnist = fetch_openml('mnist_784', cache=False)\n","X = mnist.data.astype('float32')\n","y = mnist.target.astype('int64')\n","X /= 255.0\n","print(X.shape)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"zB-u3e9taDjT"},"source":["## Split Dataset\n","\n","학습과 평가를 위한 dataset으로 나눕니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-HWWRcNjaLDi"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"sYnvqbdijWUQ"},"source":["## Pytorch Dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ypqp7zA-xRlB"},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, y):\n","        super(CustomDataset, self).__init__()\n","        self.X = X\n","        self.y = y\n","        \n","    def __getitem__(self, index):\n","        x = self.X[index]\n","        y = self.y[index]\n","        x = torch.from_numpy(x).float()\n","        y = torch.from_numpy(np.array(y)).long()\n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTr4OWatzmaU"},"outputs":[],"source":["train_dataset = CustomDataset(X_train, y_train)\n","test_dataset = CustomDataset(X_test, y_test)\n","\n","print(len(train_dataset))\n","print(train_dataset.X.shape)\n","print(len(test_dataset))\n","print(test_dataset.X.shape)"]},{"cell_type":"markdown","metadata":{"id":"51PT-uPVzE8_"},"source":["## DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2k3YVBoxRnF"},"outputs":[],"source":["batch_size = 64\n","\n","# shuffle the train data\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# do not shuffle the val \u0026 test data\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# dataset size // batch_size\n","print(len(train_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"BN65oTBk1d4T"},"source":["## Trainer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJqIwSltn9uY"},"outputs":[],"source":["class Trainer():\n","    def __init__(self, trainloader, testloader, model, optimizer, criterion, device):\n","        \"\"\"\n","        trainloader: train data's loader\n","        testloader: test data's loader\n","        model: model to train\n","        optimizer: optimizer to update your model\n","        criterion: loss function\n","        \"\"\"\n","        self.trainloader = trainloader\n","        self.testloader = testloader\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.device = device\n","        \n","    def train(self, epoch = 1):\n","        self.model.train()\n","        for e in range(epoch):\n","            running_loss = 0.0  \n","            for i, data in enumerate(self.trainloader, 0): \n","                inputs, labels = data \n","                # model에 input으로 tensor를 gpu-device로 보낸다\n","                inputs = inputs.to(self.device)  \n","                labels = labels.to(self.device)\n","                # zero the parameter gradients\n","                self.optimizer.zero_grad()    \n","                # forward + backward + optimize\n","                outputs = self.model(inputs) \n","                loss = self.criterion(outputs, labels)  \n","                loss.backward() \n","                self.optimizer.step() \n","                running_loss += loss.item()\n","            \n","            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n","            running_loss = 0.0\n","        \n","    def test(self):\n","        self.model.eval() \n","        correct = 0\n","        for inputs, labels in self.testloader:\n","            inputs = inputs.to(self.device)\n","            labels = labels.to(self.device)\n","            output = self.model(inputs) \n","            pred = output.max(1, keepdim=True)[1] # get the index of the max \n","            correct += pred.eq(labels.view_as(pred)).sum().item()\n","        test_acc = correct / len(self.testloader.dataset)\n","        print('test_acc: %.3f' %(test_acc))"]},{"cell_type":"markdown","metadata":{"id":"T1GnKJCB4T_Q"},"source":["# 2. Activation Function\n","\n","이번 section에서는 가장 대표적으로 사용되는 sigmoid function과 relu function을 사용해보고 비교해보도록 하겠습니다.\n","\n","![](https://drive.google.com/uc?export=view\u0026id=1xfJBd9v9L_RgXGf8urNrYpb40zXU6gea)\n"]},{"cell_type":"markdown","metadata":{"id":"uUhK8GHx0704"},"source":["- input: 784\n","- hidden: 32 or (32, 32)\n","- output: 10\n","- **activation: sigmoid or relu**\n","- optimizer: sgd\n","- loss: cross-entropy"]},{"cell_type":"markdown","metadata":{"id":"7zPmZhpZlZkQ"},"source":["## 2-layer Network + Sigmoid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPfV0OTc4Xdr"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=32, \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.sigmoid(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKqcfL4_qK6Q"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgD1bTOzqK-n"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"yKxP2nzvVC_O"},"source":["## 2-layer Network + ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gRfskIWWQEf"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=32, \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DVKoXvlYryMK"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"z0wcOPU_ryOg"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"2RyAkEQEr-OV"},"source":["#### Q1. Activation Function에 따라 성능의 차이가 있나요? 있다면, 왜 차이가 발생했을까요?\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2D2tIM62sUW4"},"source":["## 3-layer Network + Sigmoid"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"29TauDy4ryQ0"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=(32,32), \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n","        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n","        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.sigmoid(x)\n","        x = self.fc2(x)\n","        x = F.sigmoid(x)\n","        x = self.fc3(x)\n","        return x\n","\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5oS8LPa6ryVd"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZfCOr5-lryZy"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"0zPtZFsZtAVy"},"source":["## 3-layer Network + ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xucFjeWLryd-"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=(32,32), \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n","        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n","        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uQPzJum6t34S"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rfVnHhN9t4vC"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"ICv5Wc_TuH3B"},"source":["#### Q2. Activation function 별로 Layer 수를 늘리는 것이 성능이 어떻게 변하나요? 양상이 다르게 나타난다면 왜 그럴까요?"]},{"cell_type":"markdown","metadata":{"id":"54oz80tfuH5M"},"source":["#### Q3. Activation function이 존재하지 않는다면 어떤 일이 일어날까요?"]},{"cell_type":"markdown","metadata":{"id":"XmrGO-uru01w"},"source":["# 3. Optimization\n","\n","이번 section에서는 sgd, momentum, Adam등의 optimizer를 사용해보고 성능을 비교해보도록 하겠습니다.\n","\n","![](https://drive.google.com/uc?export=view\u0026id=1xfCTx8xj4zoaombrK2bSN9nv0Z3r95jp)\n"]},{"cell_type":"markdown","metadata":{"id":"3jjuv9XW2Cij"},"source":["- input: 784\n","- hidden: (32, 32)\n","- output: 10\n","- activation: relu\n","- **optimizer: sgd or momentum or adam**\n","- loss: cross-entropy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WxhHMDjHxRV4"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=(32,32), \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n","        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n","        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"xlkMXZfKxpRg"},"source":["## 3-layer Network + ReLU + SGD"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fCDbH1Bbxify"},"outputs":[],"source":["model = MLP()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lchz9vtUxkiD"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ksQiJFqxls_"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"b1nhBnqWxw4a"},"source":["## 3-layer Network + ReLU + Momentum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idG8_h_QxmQi"},"outputs":[],"source":["model = MLP()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDNAysVqxxOk"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0U2s0hux_n6"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"SZobOWhPxytT"},"source":["## 3-layer Network + ReLU + Adam\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7xVOWgZxzoS"},"outputs":[],"source":["model = MLP()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6R4pzcKPyFBi"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgAEpCJ_yHAi"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"markdown","metadata":{"id":"wCeNbNhIyyR6"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"qOLVGSb7yyWW"},"source":["#### Q4. Optimizer 별로 수렴 속도가 어떻게 다른가요? \n","##### Q4.1 수렴 속도가 다르다면 sgd와 momentum의 차이는 왜 발생할까요? \n","##### Q4.2 수렴 속도가 다르다면 momentum과 Adam의 차이는 왜 발생할까요?"]},{"cell_type":"markdown","metadata":{"id":"ZNP78kE2zbPQ"},"source":["## 4. Regularization\n","\n","이번 section에서는 image data에서 주로 사용되는 batch-normalization을 어떻게 사용하는지를 확인해보겠습니다.\n","\n","![](https://drive.google.com/uc?export=view\u0026id=1xZSWZiSxuGZAsonghidhTSfUEYiuxRtN)"]},{"cell_type":"markdown","metadata":{"id":"G1YretVf2eRy"},"source":["- input: 784\n","- hidden: 32 or (32, 32)\n","- output: 10\n","- activation: relu\n","- optimizer: adam\n","- **regularizer: batch_norm**\n","- loss: cross-entropy"]},{"cell_type":"markdown","metadata":{"id":"Qmvn2oNj0Spe"},"source":["## 3-layer Network + ReLU + Adam + batch_norm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FBt1qcYzrph"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 hidden_dim=(32,32), \n","                 output_dim=10):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n","        self.bn1 = nn.BatchNorm1d(hidden_dim[0])\n","        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n","        self.bn2 = nn.BatchNorm1d(hidden_dim[1])\n","        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VSAzG4uz_4i"},"outputs":[],"source":["model = MLP()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDYfHC9x0BKy"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdpSN6uu0CZy"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qDotwtf3m-Q"},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","count_parameters(model)"]},{"cell_type":"markdown","metadata":{"id":"1WSYxs4F0Kbt"},"source":["#### Q5. Batch-normalization을 사용하기 전 후로 성능이 어떻게 변화했나요? 왜 이러한 변화가 일어났을까요?\n"]},{"cell_type":"markdown","metadata":{"id":"-6xu4cQl0fOy"},"source":["# 5. Fully-Connected Layer vs Convolution Layer\n","\n","지금까지 model의 다양한 node를 바꿔가며 mnist의 성능 변화를 확인해보는 실습을 진행해 보았습니다. \\\\\n","비록, fully-connected network가 mnist 데이터에서 높은 성능을 내는데는 문제가 없었지만, 모든 layer를 fully-connected layer로 만드는 것은 엄청난 파라미터와 연산량을 필요로 하기 때문에 더욱 큰 고화질의 이미지 데이터를 처리하는데는 적합하지 않습니다. \\\\ \n","\n","따라서, 이번 section에서는 이미지 데이터 처리에 주로 사용되는 convolution layer를 사용해보고 파라미터 수와 성능이 어떻게 변화하는지 확인해보도록 하겠습니다. "]},{"cell_type":"markdown","metadata":{"id":"VBH4WROS2-H4"},"source":["## Convolution Operation\n","\n","![](https://drive.google.com/uc?export=view\u0026id=1xdjTf4ab0P8qfu_TaLJ4TZzt5sk3twS6)\n"]},{"cell_type":"markdown","metadata":{"id":"u86dyWA98qQ_"},"source":["### Q6. Input이 (H, W, C) 일 때, stride S의 2개의 (F * F) convolutional filter를 적용하면 output이 어떻게 되나요?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tfEDx7429cL"},"outputs":[],"source":["class Conv(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 output_dim=10):\n","        super(Conv, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1,\n","                               out_channels=8,\n","                               kernel_size=7,\n","                               stride=2)\n","        self.conv2 = nn.Conv2d(in_channels=8,\n","                               out_channels=8,\n","                               kernel_size=7,\n","                               stride=2)\n","        self.fc = nn.Linear(3*3*8, output_dim)\n","\n","    def forward(self, x):\n","        # should reshape data into image\n","        x = x.reshape(-1, 1, 28, 28)\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = x.reshape(-1, 3*3*8)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2QbRqEz-FzB"},"outputs":[],"source":["model = Conv()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTRB0_15-eYy"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JuFiCnDa-fpC"},"outputs":[],"source":["trainer.test()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRVwFbhU-8TZ"},"outputs":[],"source":["count_parameters(model)"]},{"cell_type":"markdown","metadata":{"id":"Ayzu25pm_KNH"},"source":["##### Q7. covolution operation은 image데이터를 다루는데 있어서 fully-connected layer에 비해 어떤 점에서 효과적일까요?\n"]},{"cell_type":"markdown","metadata":{"id":"bdCwjzXX_-jU"},"source":["## 6. Do It By Yourself\n","\n","위에서 했던 실습들과 수업에 배웠던 다양한 network component들을 참조해서 20,000개 이하의 파라미터로 98%의 accuracy를 달성해보세요!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOqAaJkGAAuC"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, \n","                 input_dim=784, \n","                 output_dim=10):\n","      super(CustomModel, self).__init__()\n","      pass\n","\n","    def forward(self, x):\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2B-6gww_Af0E"},"outputs":[],"source":["model = CustomModel()\n","if count_parameters(model) \u003e 20000:\n","  raise AssertionError"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcA3XbRUAaUh"},"outputs":[],"source":["#optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJBKdQTyAd24"},"outputs":[],"source":["trainer = Trainer(trainloader = train_dataloader,\n","                  testloader = test_dataloader,\n","                  model = model,\n","                  criterion = criterion,\n","                  optimizer = optimizer,\n","                  device = device)\n","\n","trainer.train(epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0URQgBu_AfJB"},"outputs":[],"source":["trainer.test()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"[HW2]TrainingNN.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}