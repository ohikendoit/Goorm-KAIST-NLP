{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[HW1.1]PytorchTutorial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jR26RFkwXtvi"},"source":["# **[HW1.1] PyTorch Tutorial**\n","1. Install packages\n","2. Tensor\n","3. AutoGrad\n","\n","딥러닝 실습은, 수업시간에 배웠던 개념들을 직접 코드로 옮겨보며 이를 폭넓게 이해하는 데에 초점을 맞추고 있습니다. 실습에서 사용한 예시 외에도, 다양한 architecture를 직접 구성해보며 각 node와 function의 역할을 명확히 이해해보시길 바랍니다.\n","\n","이번 실습에서는 딥러닝 모델을 만들때 사용하는 PyTorch library에 대한 기본 개념들을 익혀보도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"e4iquuOQj1g9"},"source":["# 1. Import packages\n","\n","> 필요한 package를 설치하고 import합니다"]},{"cell_type":"markdown","metadata":{"id":"zpvlE_XOWS33"},"source":["런타임의 유형을 변경해줍니다.\n","\n","상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n","\n","변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"cqVdEuPQzMAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150771822,"user_tz":-540,"elapsed":4182,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"39dc65b4-2727-4823-8311-de5437fb06ff"},"source":["import torch\n","print(torch.__version__)\n","print(torch.cuda.is_available())"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu102\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"2o3-HPdHLZma","executionInfo":{"status":"ok","timestamp":1631150772098,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy as sp\n","\n","np.set_printoptions(precision=3)\n","np.set_printoptions(suppress=True)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMkIJgfEl9kD"},"source":["# 2. Tensor operations\n"]},{"cell_type":"markdown","metadata":{"id":"IxQqLw-Dl_Zw"},"source":["텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n","\n","GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다. "]},{"cell_type":"markdown","metadata":{"id":"P8XqtZa8sXsw"},"source":["##텐서 초기화하기\n","\n","데이터로부터 직접 생성하기"]},{"cell_type":"code","metadata":{"id":"oCnmrA9ltYs0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772099,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"e6926421-62db-40c2-8778-5d6c4d0b1031"},"source":["data = [[1, 2],[3, 4]]\n","x = torch.tensor(data)\n","x"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"FZx51U6fUXSc"},"source":["Numpy array로부터 생성하기"]},{"cell_type":"code","metadata":{"id":"I5m4qus2UnoL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772100,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"41007dbc-21e0-4dac-a7ca-c947a52319a5"},"source":["np_array = np.array(data)\n","x = torch.from_numpy(np_array)\n","x"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"8BfwipaTYEFI"},"source":["Tensor에서 Numpy array로 변환하기"]},{"cell_type":"code","metadata":{"id":"upkEJ9mBMCOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772100,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"718eb243-da44-4c4f-8351-118a37f8bec8"},"source":["x.numpy()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2],\n","       [3, 4]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"obZ-A5rxYOSx"},"source":["다른 텐서와 같은 모양의 텐서 초기화하기"]},{"cell_type":"code","metadata":{"id":"RkJRGOaEyyc0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772375,"user_tz":-540,"elapsed":281,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"7304fbd9-1b0d-4a24-9c2b-070b278c92f0"},"source":["x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.0179, 0.0047],\n","        [0.9736, 0.1019]]) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"D1E5bEPHZskg"},"source":["주어진 shape으로 초기화하기"]},{"cell_type":"code","metadata":{"id":"pk1OASeazKtN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772376,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"099fbb2e-0b5e-4ee6-c5ad-274a043cb510"},"source":["shape = (3,4)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.2703, 0.5848, 0.0052, 0.9647],\n","        [0.3242, 0.3206, 0.5032, 0.2871],\n","        [0.6243, 0.5831, 0.5295, 0.1740]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"zB-u3e9taDjT"},"source":["## 텐서의 속성\n","\n","텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"-HWWRcNjaLDi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150772377,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"a8ec27e9-75c8-4491-f822-3f87d70ca430"},"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}]},{"cell_type":"markdown","metadata":{"id":"3A7LymV5aYEA"},"source":["아래와 같이 cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있습니다."]},{"cell_type":"code","metadata":{"id":"mKvYqt3ZaOXZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781912,"user_tz":-540,"elapsed":9540,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"22fd0a9c-1ec2-42ee-b935-fe53c36131c7"},"source":["device = torch.device('cuda')\n","tensor = tensor.to(device)\n","print(f\"Device tensor is stored on: {tensor.device}\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Device tensor is stored on: cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"01vssH7n24cq"},"source":["## 텐서 연산"]},{"cell_type":"markdown","metadata":{"id":"nqON2YtYczmS"},"source":["Numpy식의 인덱싱과 슬라이싱"]},{"cell_type":"code","metadata":{"id":"UOv_w4LhjTDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781912,"user_tz":-540,"elapsed":44,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"c7e3aa29-79a5-4166-fb6a-2bab97043b83"},"source":["tensor = torch.ones(3, 4)\n","tensor[:,1] = 0\n","print(tensor)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"jR0J9p1WkpHO"},"source":["텐서 합치기"]},{"cell_type":"code","metadata":{"id":"s68HmhqlknkX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781913,"user_tz":-540,"elapsed":39,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"7e8a2091-f0b5-40f2-eb0d-a654824a5fca"},"source":["t1 = torch.cat([tensor, tensor, tensor], dim=0)\n","print(t1)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"code","metadata":{"id":"tYxrFYAjbQuS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781913,"user_tz":-540,"elapsed":33,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"9006421f-01fa-482b-e93d-cf875800c078"},"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ThLzN1ONbV-p"},"source":["텐서 곱하기"]},{"cell_type":"code","metadata":{"id":"hCMMXj8ejXVG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781913,"user_tz":-540,"elapsed":30,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"29a7d000-7b34-43bd-fb5e-4735b79e0f13"},"source":["# 요소별 곱(element-wise product)을 계산합니다\n","print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n","\n","# 다른 문법:\n","print(f\"tensor * tensor \\n {tensor * tensor}\")"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.mul(tensor) \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor * tensor \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"9752P1u90enu"},"source":["텐서간 matrix multiplication 진행하기"]},{"cell_type":"code","metadata":{"id":"RhOPv757T4NG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781915,"user_tz":-540,"elapsed":29,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"921a6852-a81d-4bc4-dd45-3cc4d024b1bd"},"source":["print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n","# 다른 문법:\n","print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.matmul(tensor.T) \n"," tensor([[3., 3., 3.],\n","        [3., 3., 3.],\n","        [3., 3., 3.]]) \n","\n","tensor @ tensor.T \n"," tensor([[3., 3., 3.],\n","        [3., 3., 3.],\n","        [3., 3., 3.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"sC_i0POOIf0M"},"source":["# 3. AUTOGRAD"]},{"cell_type":"markdown","metadata":{"id":"5tQLTW4vcRJK"},"source":["PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다. \n","이는 모든 node에 대한 미분 값을 자동으로 계산해주게 됩니다.\n","\n","입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"-b3w8_NGdCL1"},"source":["## 입력 및 파라미터 초기화"]},{"cell_type":"code","metadata":{"id":"52zAKX7zLl7n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781915,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"0288f7e0-ccea-46e0-9fe8-dc4e7bf095dd"},"source":["x = torch.ones(5)  # input tensor\n","y = torch.zeros(3)  # expected output\n","w = torch.randn(5, 3, requires_grad=True)\n","b = torch.randn(3, requires_grad=True)\n","print(x)\n","print(y)\n","print(w)\n","print(b)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.])\n","tensor([0., 0., 0.])\n","tensor([[-0.0802, -1.1405, -0.7121],\n","        [-0.1358, -0.6840,  0.4886],\n","        [-0.2076, -0.5850,  0.4255],\n","        [ 0.4640, -2.6366, -1.5647],\n","        [-0.1706,  0.4467, -1.2228]], requires_grad=True)\n","tensor([1.7224, 2.3998, 0.0393], requires_grad=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"FfSzTTVUeb06"},"source":["## Forward"]},{"cell_type":"code","metadata":{"id":"09v6hrSIecG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781915,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"422a1d58-6d9d-4fc5-bf6b-0cb499e1d881"},"source":["z = torch.matmul(x,w)+b\n","z"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.5923, -2.1996, -2.5461], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"1R19jHY9Pemt"},"source":["## Loss Function\n","\n","PyTorch에서는 node를 크게 2가지의 방법의 api를 활용해서 사용합니다.\n","\n","1. [torch.nn](https://pytorch.org/docs/stable/nn.html)\n","2. [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n","\n","torch.nn은 사전에 node를 초기화 시켜놓고, 해당 node에 텐서를 통과시켜 값을 받는 형태인 반면, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n","\n","코딩 스타일에 맞춰 원하시는 api를 선택하셔서 사용하시면 됩니다.\n"]},{"cell_type":"code","metadata":{"id":"-TQe1Nw8QLMu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781916,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"5a96a6cc-3466-405c-dda8-0b0ae9607315"},"source":["loss_fn = torch.nn.BCEWithLogitsLoss()\n","loss = loss_fn(z, y)\n","loss"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.6527, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"gihsaH3ULCRN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150781916,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"0c536445-2207-45e7-9739-be4e9252f0e4"},"source":["loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n","loss"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.6527, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"OCsd5yep3-sj"},"source":["## Backward"]},{"cell_type":"markdown","metadata":{"id":"gfNejCDye61c"},"source":["모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다. \n","이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"]},{"cell_type":"code","metadata":{"id":"OptZdnLSu5vC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150782260,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"5fd9bf69-4b3e-4f4c-a17d-ada213bee6d4"},"source":["loss.backward()\n","print(x.grad)\n","print(w.grad)\n","print(b.grad)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","tensor([[0.2770, 0.0333, 0.0242],\n","        [0.2770, 0.0333, 0.0242],\n","        [0.2770, 0.0333, 0.0242],\n","        [0.2770, 0.0333, 0.0242],\n","        [0.2770, 0.0333, 0.0242]])\n","tensor([0.2770, 0.0333, 0.0242])\n"]}]},{"cell_type":"markdown","metadata":{"id":"XFE4lc-lfYtf"},"source":["기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"]},{"cell_type":"code","metadata":{"id":"MaiqxruWT_so","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631150782261,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyuk In Choi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07467313004163826392"}},"outputId":"d6a94e99-48c8-44ae-ad0b-176208db377e"},"source":["z = torch.matmul(x, w)+b\n","print(z.requires_grad)\n","\n","with torch.no_grad():\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"i_NqQRDaKqU6"},"source":["# Reference\n","\n","1. https://tutorials.pytorch.kr/index.html"]}]}